{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed3b7d82",
   "metadata": {},
   "source": [
    "##### Manikanta Gangam\n",
    "##### E21CSEU0947\n",
    "##### EB13\n",
    "##### Lab 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4772068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9e5889",
   "metadata": {},
   "source": [
    "##### Task 1: Data Preparation on the given corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb8e371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"The sun sets over the horizon, painting the sky with hues of orange and pink.\",\n",
    "    \"In the heart of the forest, a gentle breeze rustles the leaves.\",\n",
    "    \"She walked along the sandy shore, feeling the cool water on her feet.\",\n",
    "    \"The old bookshop on the corner is filled with stories waiting to be discovered.\",\n",
    "    \"As the rain falls outside, I sit by the window with a cup of hot tea.\"\n",
    "]\n",
    "\n",
    "tokenized_corpus = [sentence.split() for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55eb0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'sun', 'sets', 'over', 'the', 'horizon,', 'painting', 'the', 'sky', 'with', 'hues', 'of', 'orange', 'and', 'pink.'], ['In', 'the', 'heart', 'of', 'the', 'forest,', 'a', 'gentle', 'breeze', 'rustles', 'the', 'leaves.'], ['She', 'walked', 'along', 'the', 'sandy', 'shore,', 'feeling', 'the', 'cool', 'water', 'on', 'her', 'feet.'], ['The', 'old', 'bookshop', 'on', 'the', 'corner', 'is', 'filled', 'with', 'stories', 'waiting', 'to', 'be', 'discovered.'], ['As', 'the', 'rain', 'falls', 'outside,', 'I', 'sit', 'by', 'the', 'window', 'with', 'a', 'cup', 'of', 'hot', 'tea.']]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e993328",
   "metadata": {},
   "source": [
    "##### Task 2: Build the N-Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f8cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(words, n):\n",
    "    ngrams = []\n",
    "    for i in range(len(words) - n + 1):\n",
    "        ngram = tuple(words[i:i+n])\n",
    "        ngrams.append(ngram)\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2000c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_model(tokenized_corpus, n):\n",
    "    ngram_model = defaultdict(dict)\n",
    "    \n",
    "    for sentence in tokenized_corpus:\n",
    "        ngrams = generate_ngrams(sentence, n)\n",
    "        for i in range(len(ngrams) - 1):\n",
    "            prefix = ngrams[i][:-1]\n",
    "            next_word = ngrams[i][-1]\n",
    "            if next_word in ngram_model[prefix]:\n",
    "                ngram_model[prefix][next_word] += 1\n",
    "            else:\n",
    "                ngram_model[prefix][next_word] = 1\n",
    "                \n",
    "    return ngram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6e02a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_model = build_ngram_model(tokenized_corpus, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "369fea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da1d4fc",
   "metadata": {},
   "source": [
    "##### Task 3: Generate Text with Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbef10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word_with_smoothing(ngram_model, prefix):\n",
    "    if prefix in ngram_model:\n",
    "        next_words = ngram_model[prefix]\n",
    "        total_count = sum(next_words.values())\n",
    "        probabilities = {word: (count + 1) / (total_count + len(next_words)) for word, count in next_words.items()}\n",
    "        return random.choices(list(probabilities.keys()), list(probabilities.values()))[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d227243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_with_unseen_data(ngram_model, n, test_prefix, max_length=10):\n",
    "    generated_text = list(test_prefix)\n",
    "    \n",
    "    for _ in range(max_length - n + 1):\n",
    "        next_word = predict_next_word_with_smoothing(ngram_model, tuple(generated_text[-n+1:]))\n",
    "        if next_word is not None:\n",
    "            generated_text.append(next_word)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return \" \".join(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "916cad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prefix_1 = [\"The\", \"rain\", \"falls\"]\n",
    "test_prefix_2 = [\"The\", \"old\", \"bookshop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8977058",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text_1 = generate_text_with_unseen_data(ngram_model, n=2, test_prefix=test_prefix_1)\n",
    "generated_text_2 = generate_text_with_unseen_data(ngram_model, n=2, test_prefix=test_prefix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4dd541f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text 1: The rain falls outside, I sit by the sandy shore, feeling the\n",
      "Generated Text 2: The old bookshop on the sandy shore, feeling the window with stories\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated Text 1:\", generated_text_1)\n",
    "print(\"Generated Text 2:\", generated_text_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
