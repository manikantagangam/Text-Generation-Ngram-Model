{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44af6a8",
   "metadata": {},
   "source": [
    "##### Manikanta Gangam\n",
    "##### E21CSEU0947\n",
    "##### EB13\n",
    "##### Lab 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f7310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ec68a6",
   "metadata": {},
   "source": [
    "##### Task 1: Data Preparation on the given corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255f4829",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"The sun sets over the horizon, painting the sky with hues of orange and pink.\",\n",
    "    \"In the heart of the forest, a gentle breeze rustles the leaves.\",\n",
    "    \"She walked along the sandy shore, feeling the cool water on her feet.\",\n",
    "    \"The old bookshop on the corner is filled with stories waiting to be discovered.\",\n",
    "    \"As the rain falls outside, I sit by the window with a cup of hot tea.\"\n",
    "]\n",
    "\n",
    "tokenized_corpus = [sentence.split() for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2939d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbbd4dd",
   "metadata": {},
   "source": [
    "##### Task 2: Build the N-Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758fbbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(words, n):\n",
    "    ngrams = []\n",
    "    for i in range(len(words) - n + 1):\n",
    "        ngram = tuple(words[i:i+n])\n",
    "        ngrams.append(ngram)\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e51adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_model(tokenized_corpus, n):\n",
    "    ngram_model = defaultdict(dict)\n",
    "    \n",
    "    for sentence in tokenized_corpus:\n",
    "        ngrams = generate_ngrams(sentence, n)\n",
    "        for i in range(len(ngrams) - 1):\n",
    "            prefix = ngrams[i][:-1]\n",
    "            next_word = ngrams[i][-1]\n",
    "            if next_word in ngram_model[prefix]:\n",
    "                ngram_model[prefix][next_word] += 1\n",
    "            else:\n",
    "                ngram_model[prefix][next_word] = 1\n",
    "                \n",
    "    return ngram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a9e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_model = build_ngram_model(tokenized_corpus, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72377287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e7d9c3",
   "metadata": {},
   "source": [
    "##### Task 3: Generate Text with Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4612201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word_with_smoothing(ngram_model, prefix):\n",
    "    if prefix in ngram_model:\n",
    "        next_words = ngram_model[prefix]\n",
    "        total_count = sum(next_words.values())\n",
    "        probabilities = {word: (count + 1) / (total_count + len(next_words)) for word, count in next_words.items()}\n",
    "        max_prob_word = max(probabilities, key=probabilities.get)\n",
    "        return max_prob_word\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ff0c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_with_unseen_data(ngram_model, n, test_prefix):\n",
    "    next_word = predict_next_word_with_smoothing(ngram_model, tuple(test_prefix[-n+1:]))\n",
    "    return next_word if next_word is not None else \"No prediction available\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beae6aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input_1 = input(\"Enter a sentence for test prefix 1: \")\n",
    "user_input_2 = input(\"Enter a sentence for test prefix 2: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1e5333",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input_1 = user_input_1.split()\n",
    "tokenized_input_2 = user_input_2.split()\n",
    "generated_text_user_input_1 = generate_text_with_unseen_data(ngram_model, n=2, test_prefix=tokenized_input_1)\n",
    "generated_text_user_input_2 = generate_text_with_unseen_data(ngram_model, n=2, test_prefix=tokenized_input_2)\n",
    "generated_sentence_1 = \" \".join(tokenized_input_1 + [generated_text_user_input_1])\n",
    "generated_sentence_2 = \" \".join(tokenized_input_2 + [generated_text_user_input_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generated Text for User Input 1:\", generated_sentence_1)\n",
    "print(\"Generated Text for User Input 2:\", generated_sentence_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
